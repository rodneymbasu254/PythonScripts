{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c69d6a9c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.473869,
     "end_time": "2024-01-11T13:10:01.517376",
     "exception": false,
     "start_time": "2024-01-11T13:10:01.043507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9895b0d",
   "metadata": {
    "papermill": {
     "duration": 16.770438,
     "end_time": "2024-01-11T13:10:18.291369",
     "exception": false,
     "start_time": "2024-01-11T13:10:01.520931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f389b77a",
   "metadata": {
    "papermill": {
     "duration": 17.513835,
     "end_time": "2024-01-11T13:10:35.808530",
     "exception": false,
     "start_time": "2024-01-11T13:10:18.294695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/kaggle/input/university-chatbot-dataset/intents.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# load data from JSON file\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/input/university-chatbot-dataset/intents.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# extract text and intent from data\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/university-chatbot-dataset/intents.json'"
     ]
    }
   ],
   "source": [
    "# load data from JSON file\n",
    "with open('/kaggle/input/university-chatbot-dataset/intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# extract text and intent from data\n",
    "texts = []\n",
    "intents = []\n",
    "for intent in data['intents']:\n",
    "    for text in intent['text']:\n",
    "        texts.append(text)\n",
    "        intents.append(intent['intent'])\n",
    "\n",
    "# tokenize text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "encoded_texts = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "# save tokenizer\n",
    "import pickle\n",
    "\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "# pad sequences to have equal length\n",
    "max_len = max([len(x) for x in encoded_texts])\n",
    "padded_texts = pad_sequences(encoded_texts, maxlen=max_len, padding='post')\n",
    "\n",
    "# create label encoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# fit and transform the intents to integer labels\n",
    "encoded_intents = le.fit_transform(intents)\n",
    "\n",
    "# get the number of unique labels\n",
    "num_intents = len(le.classes_)\n",
    "\n",
    "# apply one-hot encoding to the integer labels\n",
    "encoded_intents = tf.one_hot(encoded_intents, depth=num_intents)\n",
    "\n",
    "# define model architecture\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=max_len)(input_layer)\n",
    "lstm_layer = LSTM(128)(embedding_layer)\n",
    "output_layer = Dense(num_intents, activation='softmax')(lstm_layer)\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# train model\n",
    "model.fit(padded_texts, encoded_intents, epochs=50, batch_size=16)\n",
    "\n",
    "# save model\n",
    "model.save('chatbot_model34.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72390e8",
   "metadata": {
    "papermill": {
     "duration": 0.49394,
     "end_time": "2024-01-11T13:10:36.343073",
     "exception": false,
     "start_time": "2024-01-11T13:10:35.849133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# load data from JSON file\n",
    "with open('/kaggle/input/university-chatbot-dataset/intents.json') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# extract text and intent from data\n",
    "texts = []\n",
    "intents = []\n",
    "for intent in data['intents']:\n",
    "    for text in intent['text']:\n",
    "        texts.append(text)\n",
    "        intents.append(intent['intent'])\n",
    "\n",
    "# tokenize text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# load saved model\n",
    "model = load_model('/kaggle/working/chatbot_model34.h5')\n",
    "\n",
    "# define maximum sequence length\n",
    "max_len = model.input_shape[1]\n",
    "\n",
    "# create label encoder object\n",
    "le = LabelEncoder()\n",
    "le.fit(intents)\n",
    "\n",
    "# create inverse mapping of label encoder for intent prediction\n",
    "intent_mapping = {i: label for i, label in enumerate(le.classes_)}\n",
    "\n",
    "# start chatbot interaction\n",
    "print('Welcome to the chatbot! Type \"quit\" to exit.')\n",
    "while True:\n",
    "    # get user input\n",
    "    #user_input = input('You: ').lower().strip()  #for user input run this line\n",
    "    user_input = \"quit\"\n",
    "    \n",
    "    # check if user wants to quit\n",
    "    if user_input == 'quit':\n",
    "        break\n",
    "    \n",
    "    # encode user input text\n",
    "    encoded_input = tokenizer.texts_to_sequences([user_input])\n",
    "    padded_input = pad_sequences(encoded_input, maxlen=max_len, padding='post')\n",
    "    \n",
    "    # predict intent\n",
    "    intent_prob = model.predict(padded_input)[0]\n",
    "    intent_idx = np.argmax(intent_prob)\n",
    "    intent_label = le.inverse_transform([intent_idx])[0]\n",
    "    \n",
    "    # retrieve response\n",
    "    for intent in data['intents']:\n",
    "        if intent['intent'] == intent_label:\n",
    "            response = np.random.choice(intent['responses'])\n",
    "            print('Chatbot:', response)\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae6efbb",
   "metadata": {
    "papermill": {
     "duration": 0.037296,
     "end_time": "2024-01-11T13:10:36.420154",
     "exception": false,
     "start_time": "2024-01-11T13:10:36.382858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d157b81-207f-48ed-9b84-4ddfde4bec43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3757279,
     "sourceId": 6500031,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.55019,
   "end_time": "2024-01-11T13:10:38.975530",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-11T13:09:57.425340",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
